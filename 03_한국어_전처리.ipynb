{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1o_ChYMpLTeTsUoiJe2D_TPIZYcvSQx_c",
      "authorship_tag": "ABX9TyNGka0m+XqdmjSA6/MuOur3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgr1118/Sentence-Embedding-Using-Korean-Corpora/blob/main/03_%ED%95%9C%EA%B5%AD%EC%96%B4_%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 한국어 전처리\n",
        "- 3장에서는 임베딩 학습을 위한 한국어 데이터 전처리 과정을 다룬다. 웹 문서나 json 같은 형태의 파일을 텍스트 파일로 바꾸고 여기에 형태소 분석을 실시하는 방법을 설명한다. 형태소 분석 방법에는 국어학 전문가들이 태깅한 데이터로 학습된 모델로 분석하는 지도 학습 기법, 우리가 가진 말뭉치의 패텅을 학습한 모델을 적용하는 비지도 학습 기법 등이 있다.\n",
        "\n",
        "## 3.1 데이터 확보\n",
        "- 임베딩 학습용 말뭉치는 직접 만들거나, 웹 스크래핑을 하여 모을 수 있다. 이 교재에서는 이미 공개돼있는 말뭉치 데이터를 활용\n",
        "\n",
        "- 임베딩에 자연어 의미를 함축하는 비법은 자연어의 통계적 패턴 정보를 통째로 임베딩에 넣는 것이다. 자연어의 의미는 해당 언어 화자들이 실제 사용하는 일상 언어에서 드러나기 때문이다. 임베딩을 만들 때 쓰는 통계 정보는 아래 3가지 있다.\n",
        "\n",
        "### 3.1.1 한국어 위키백과\n",
        "- 한국어 위키백과 raw data를 사용하려면 도커 컨테이너 bash shell을 사용하거나 pythn 상에서 코드로 불러 올 수 있다.\n",
        "\n",
        "코드 3-1 bash 한국어 위키백과 다운로드\n",
        "- git pull origin master\n",
        "- bash preprocess.sh dump-raw-wiki\n",
        "\n"
      ],
      "metadata": {
        "id": "KcPzAumlHIkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/MyDrive/Book/Sentence Embedding Using Korean Corpora/data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tno1ZiPcU_T",
        "outputId": "849fa68e-79df-45fa-89eb-ff918036ea64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Book/Sentence Embedding Using Korean Corpora/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드 3-1 한국어 위키백과 다운로드\n",
        "!pip install wikiextractor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXblyuFhwdhp",
        "outputId": "cb7471ae-0dac-4ff3-e9fb-1488a74f528d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wikiextractor\n",
            "  Downloading wikiextractor-3.0.6-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wikiextractor\n",
            "Successfully installed wikiextractor-3.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab에 Mecab 설치\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "id": "tkdFos0Nw5g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://dumps.wikimedia.org/kowiki/latest/kowiki-latest-pages-articles.xml.bz2\n",
        "# kowiki-latest-pages-articles.xml.bz2.1이 다운되는 현상이 발생하여 kowiki-latest-pages-articles.xml.bz2를 직접적으로 다운로드하여 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OHGFaqtw99m",
        "outputId": "51e62838-643a-4795-d82f-de31dcce657c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-18 06:45:10--  https://dumps.wikimedia.org/kowiki/latest/kowiki-latest-pages-articles.xml.bz2\n",
            "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.142, 2620:0:861:2:208:80:154:142\n",
            "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 889750893 (849M) [application/octet-stream]\n",
            "Saving to: ‘kowiki-latest-pages-articles.xml.bz2.1’\n",
            "\n",
            "kowiki-latest-pages 100%[===================>] 848.53M  4.17MB/s    in 3m 22s  \n",
            "\n",
            "2023-03-18 06:48:32 (4.21 MB/s) - ‘kowiki-latest-pages-articles.xml.bz2.1’ saved [889750893/889750893]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 위키익스트랙터를 사용하여 위키피디아 덤프를 파싱\n",
        "!python -m wikiextractor.WikiExtractor kowiki-latest-pages-articles.xml.bz2"
      ],
      "metadata": {
        "id": "FvxX4MCVxAi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQbwBcOIdMcM",
        "outputId": "afd4066e-973f-4b6e-c422-2fb85137b1cc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mimages\u001b[0m/                                    LICENSE\n",
            "install_mecab-ko_on_colab190912.sh         README.md\n",
            "install_mecab-ko_on_colab_light_220429.sh  \u001b[01;34mtext\u001b[0m/\n",
            "kowiki-latest-pages-articles.xml.bz2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드 3-2 한국어 위키백과 전처리\n",
        "import os\n",
        "import re\n",
        "\n",
        "os.listdir('text')"
      ],
      "metadata": {
        "id": "EH3LdnTzgfWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da49b92b-db43-4c20-d824-c77d177e8e44"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AA', 'AB', 'AC', 'AD', 'AE', 'AF', 'AG', 'AH', 'AI']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국어 위키백과 전처리\n",
        "\n",
        "from gensim.corpora import WikiCorpus, Dictionary\n",
        "from gensim.utils import to_unicode\n",
        "from gensim.corpora.wikicorpus import tokenize\n",
        "\n",
        "in_f = '/content/drive/MyDrive/Book/Sentence Embedding Using Korean Corpora/data/Mecab-ko-for-Google-Colab/kowiki-latest-pages-articles.xml.bz2'\n",
        "out_f = '/content/drive/MyDrive/Book/Sentence Embedding Using Korean Corpora/data/Mecab-ko-for-Google-Colab/precessed_wiki_ko.txt'\n",
        "output = open(out_f, 'w')\n",
        "wiki = WikiCorpus(in_f, tokenizer_func = tokenize, dictionary=Dictionary())\n",
        "i = 0\n",
        "for text in wiki.get_texts():\n",
        "    output.write(bytes(' '.join(text), 'utf-8').decode('utf-8') + '\\n')\n",
        "    i = i + 1\n",
        "    if (i % 10000 == 0):\n",
        "        print('Processed ' + str(i) + ' article')\n",
        "output.close()\n",
        "print('Processing complete!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo8LY53voUxP",
        "outputId": "f7cda785-4d52-4ea8-cb49-b0b3cd3aad56"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10000 article\n",
            "Processed 20000 article\n",
            "Processed 30000 article\n",
            "Processed 40000 article\n",
            "Processed 50000 article\n",
            "Processed 60000 article\n",
            "Processed 70000 article\n",
            "Processed 80000 article\n",
            "Processed 90000 article\n",
            "Processed 100000 article\n",
            "Processed 110000 article\n",
            "Processed 120000 article\n",
            "Processed 130000 article\n",
            "Processed 140000 article\n",
            "Processed 150000 article\n",
            "Processed 160000 article\n",
            "Processed 170000 article\n",
            "Processed 180000 article\n",
            "Processed 190000 article\n",
            "Processed 200000 article\n",
            "Processed 210000 article\n",
            "Processed 220000 article\n",
            "Processed 230000 article\n",
            "Processed 240000 article\n",
            "Processed 250000 article\n",
            "Processed 260000 article\n",
            "Processed 270000 article\n",
            "Processed 280000 article\n",
            "Processed 290000 article\n",
            "Processed 300000 article\n",
            "Processed 310000 article\n",
            "Processed 320000 article\n",
            "Processed 330000 article\n",
            "Processed 340000 article\n",
            "Processed 350000 article\n",
            "Processed 360000 article\n",
            "Processed 370000 article\n",
            "Processed 380000 article\n",
            "Processed 390000 article\n",
            "Processed 400000 article\n",
            "Processed 410000 article\n",
            "Processed 420000 article\n",
            "Processing complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BqIw7X2MoUto"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}